{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 13, 3027)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "lines = open('movie_lines.txt', encoding='utf-8',\n",
    "             errors='ignore').read().split('\\n')\n",
    "\n",
    "convers = open('movie_conversations.txt', encoding='utf-8',\n",
    "             errors='ignore').read().split('\\n')\n",
    "\n",
    "\n",
    "exchn = []\n",
    "for conver in convers:\n",
    "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n",
    "\n",
    "diag = {}\n",
    "for line in lines:\n",
    "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n",
    "\n",
    "## delete\n",
    "del(lines, convers, conver, line)\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conver in exchn:\n",
    "    for i in range(len(conver) - 1):\n",
    "        questions.append(diag[conver[i]])\n",
    "        answers.append(diag[conver[i+1]])\n",
    "\n",
    "## delete\n",
    "del(diag, exchn, conver, i)\n",
    "\n",
    "\n",
    "###############################\n",
    "#        max_len = 13         #\n",
    "###############################\n",
    "\n",
    "sorted_ques = []\n",
    "sorted_ans = []\n",
    "for i in range(len(questions)):\n",
    "    if len(questions[i]) < 13:\n",
    "        sorted_ques.append(questions[i])\n",
    "        sorted_ans.append(answers[i])\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt\n",
    "\n",
    "clean_ques = []\n",
    "clean_ans = []\n",
    "\n",
    "for line in sorted_ques:\n",
    "    clean_ques.append(clean_text(line))\n",
    "        \n",
    "for line in sorted_ans:\n",
    "    clean_ans.append(clean_text(line))\n",
    "\n",
    "\n",
    "\n",
    "## delete\n",
    "del(answers, questions, line)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "del(sorted_ans, sorted_ques)\n",
    "\n",
    "\n",
    "## trimming\n",
    "clean_ans=clean_ans[:30000]\n",
    "clean_ques=clean_ques[:30000]\n",
    "## delete\n",
    "\n",
    "\n",
    "###  count occurences ###\n",
    "word2count = {}\n",
    "\n",
    "for line in clean_ques:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "for line in clean_ans:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "\n",
    "## delete\n",
    "del(word, line)\n",
    "\n",
    "\n",
    "###  remove less frequent ###\n",
    "thresh = 5\n",
    "\n",
    "vocab = {}\n",
    "word_num = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= thresh:\n",
    "        vocab[word] = word_num\n",
    "        word_num += 1\n",
    "        \n",
    "## delete\n",
    "del(word2count, word, count, thresh)       \n",
    "del(word_num)        \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n",
    "\n",
    "\n",
    "\n",
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "x = len(vocab)\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1\n",
    "    \n",
    "    \n",
    "\n",
    "vocab['cameron'] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0\n",
    "\n",
    "## delete\n",
    "del(token, tokens) \n",
    "del(x)\n",
    "\n",
    "### inv answers dict ###\n",
    "inv_vocab = {w:v for v, w in vocab.items()}\n",
    "\n",
    "\n",
    "\n",
    "## delete\n",
    "del(i)\n",
    "\n",
    "\n",
    "\n",
    "encoder_inp = []\n",
    "for line in clean_ques:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "        \n",
    "    encoder_inp.append(lst)\n",
    "\n",
    "decoder_inp = []\n",
    "for line in clean_ans:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])        \n",
    "    decoder_inp.append(lst)\n",
    "\n",
    "### delete\n",
    "del(clean_ans, clean_ques, line, lst, word)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
    "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoder_final_output = []\n",
    "for i in decoder_inp:\n",
    "    decoder_final_output.append(i[1:]) \n",
    "\n",
    "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "del(i)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
    "\n",
    "\n",
    "\n",
    "print(decoder_final_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 152s 157ms/step - loss: 3.1051 - acc: 0.4932\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 2.7421 - acc: 0.5312\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 155s 165ms/step - loss: 2.6092 - acc: 0.5425\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 2.5355 - acc: 0.5470\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 2.4771 - acc: 0.5506\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 2.4267 - acc: 0.5534\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 152s 163ms/step - loss: 2.3813 - acc: 0.5557\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 2.3372 - acc: 0.5581\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 2.2918 - acc: 0.5603\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 150s 159ms/step - loss: 2.2484 - acc: 0.5627\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 2.2077 - acc: 0.5647\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 148s 158ms/step - loss: 2.1664 - acc: 0.5667\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 2.1250 - acc: 0.5693\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 2.0840 - acc: 0.5721\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 2.0433 - acc: 0.5762\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 155s 165ms/step - loss: 2.0033 - acc: 0.5802\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.9658 - acc: 0.5847\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 158s 168ms/step - loss: 1.9293 - acc: 0.5894\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 157s 167ms/step - loss: 1.8943 - acc: 0.5938\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 156s 167ms/step - loss: 1.8597 - acc: 0.5992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211ccb2f150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
    "\n",
    "\n",
    "enc_inp = Input(shape=(13, ))\n",
    "dec_inp = Input(shape=(13, ))\n",
    "\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "embed = Embedding(VOCAB_SIZE+1, output_dim=50, \n",
    "                  input_length=13,\n",
    "                  trainable=True                  \n",
    "                  )\n",
    "\n",
    "\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "enc_op, h, c = enc_lstm(enc_embed)\n",
    "enc_states = [h, c]\n",
    "\n",
    "\n",
    "\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "\n",
    "dense_op = dense(dec_op)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], dense_op)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n",
    "\n",
    "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 156s 166ms/step - loss: 1.8262 - acc: 0.6037\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 156s 167ms/step - loss: 1.7927 - acc: 0.6091\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 161s 171ms/step - loss: 1.7610 - acc: 0.6138\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 156s 167ms/step - loss: 1.7283 - acc: 0.6197\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 155s 165ms/step - loss: 1.6981 - acc: 0.6245\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 156s 167ms/step - loss: 1.6681 - acc: 0.6295\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 156s 166ms/step - loss: 1.6390 - acc: 0.6353\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 156s 166ms/step - loss: 1.6100 - acc: 0.6403\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 156s 166ms/step - loss: 1.5825 - acc: 0.6455\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 159s 169ms/step - loss: 1.5548 - acc: 0.6506\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 74645s 80s/step - loss: 1.5279 - acc: 0.6560\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 280s 299ms/step - loss: 1.5012 - acc: 0.6611\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 298s 317ms/step - loss: 1.4757 - acc: 0.6661\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 301s 321ms/step - loss: 1.4506 - acc: 0.6709\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 272s 290ms/step - loss: 1.4249 - acc: 0.6762\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 278s 296ms/step - loss: 1.4009 - acc: 0.6809\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 273s 291ms/step - loss: 1.3765 - acc: 0.6861\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 280s 299ms/step - loss: 1.3527 - acc: 0.6915\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 278s 296ms/step - loss: 1.3303 - acc: 0.6959\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 275s 294ms/step - loss: 1.3073 - acc: 0.7010\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 281s 299ms/step - loss: 1.2853 - acc: 0.7059\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 281s 300ms/step - loss: 1.2635 - acc: 0.7106\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 283s 302ms/step - loss: 1.2421 - acc: 0.7155\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 282s 301ms/step - loss: 1.2215 - acc: 0.7197\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 1.2007 - acc: 0.7239\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 144s 154ms/step - loss: 1.1808 - acc: 0.7292\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 156s 166ms/step - loss: 1.1610 - acc: 0.7334\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 161s 172ms/step - loss: 1.1419 - acc: 0.7372\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 157s 167ms/step - loss: 1.1232 - acc: 0.7422\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 157s 167ms/step - loss: 1.1046 - acc: 0.7463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211c9124690>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 1.0864 - acc: 0.7510\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.0701 - acc: 0.7543\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 150s 160ms/step - loss: 1.0521 - acc: 0.7585\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.0357 - acc: 0.7622\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 1.0194 - acc: 0.7663\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 1.0032 - acc: 0.7701\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 0.9885 - acc: 0.7732\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 0.9724 - acc: 0.7771\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 0.9586 - acc: 0.7801\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 0.9441 - acc: 0.7838\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 150s 160ms/step - loss: 0.9303 - acc: 0.7864\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 0.9165 - acc: 0.7900\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 0.9037 - acc: 0.7934\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 0.8906 - acc: 0.7962\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 0.8787 - acc: 0.7991\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 0.8657 - acc: 0.8024\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 0.8541 - acc: 0.8046\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 150s 160ms/step - loss: 0.8430 - acc: 0.8073\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 0.8305 - acc: 0.8107\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 0.8197 - acc: 0.8129\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 150s 160ms/step - loss: 0.8106 - acc: 0.8151\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 0.8005 - acc: 0.8171\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 0.7898 - acc: 0.8200\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 0.7795 - acc: 0.8229\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 0.7717 - acc: 0.8243\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 0.7621 - acc: 0.8262\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 150s 159ms/step - loss: 0.7526 - acc: 0.8289\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 0.7437 - acc: 0.8311\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 149s 159ms/step - loss: 0.7369 - acc: 0.8320\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 0.7266 - acc: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211dbc132d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\n",
    "enc_model = Model([enc_inp], enc_states)\n",
    "\n",
    "\n",
    "\n",
    "# decoder Model\n",
    "decoder_state_input_h = Input(shape=(400,))\n",
    "decoder_state_input_c = Input(shape=(400,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n",
    "                                    initial_state=decoder_states_inputs)\n",
    "\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "dec_model = Model([dec_inp]+ decoder_states_inputs,\n",
    "                                      [decoder_outputs]+ decoder_states)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m prev_user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m     prepro1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m     prepro1 \u001b[38;5;241m=\u001b[39m clean_text(prepro1)\n\u001b[0;32m     29\u001b[0m     prepro \u001b[38;5;241m=\u001b[39m [prepro1]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\ipykernel\\kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[1;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1179\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1180\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\ipykernel\\kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def print_chat(message, is_user=False):\n",
    "    message_class = \"user-message\" if is_user else \"chatbot-message\"\n",
    "    message_tag = \"You:\" if is_user else \"Chatbot:\"\n",
    "    message_style = \"background-color: #9cd6d5; text-align: left;\" if is_user else \"background-color: #E0E0E0; text-align: right;\"\n",
    "    message_html = f'<div class=\"message {message_class}\" style=\"margin: 10px 0; padding: 10px; border-radius: 5px; {message_style}\">' \\\n",
    "                   f'<span class=\"message-tag\" style=\"font-weight: bold; color: #1E88E5;\">{message_tag}</span> {message}</div>'\n",
    "    chat_history.append(message_html)\n",
    "    display(HTML(message_html))\n",
    "    clear_output(wait=True)\n",
    "    display(HTML(''.join(chat_history)))\n",
    "\n",
    "print(\"##########################################\")\n",
    "print(\"#       Start Chatting ver. 1.0          #\")\n",
    "print(\"##########################################\")\n",
    "\n",
    "prepro1 = \"\"\n",
    "prev_user_input = \"\"\n",
    "while True:\n",
    "    prepro1 = input(\"You: \")\n",
    "    prepro1 = clean_text(prepro1)\n",
    "    prepro = [prepro1]\n",
    "\n",
    "    txt = []\n",
    "    for x in prepro:\n",
    "        lst = []\n",
    "        for y in x.split():\n",
    "            try:\n",
    "                lst.append(vocab[y])\n",
    "            except:\n",
    "                lst.append(vocab['<OUT>'])\n",
    "        txt.append(lst)\n",
    "\n",
    "    txt = pad_sequences(txt, 13, padding='post')\n",
    "\n",
    "    stat = enc_model.predict(txt, verbose=0)\n",
    "\n",
    "    empty_target_seq = np.zeros((1, 1))\n",
    "    empty_target_seq[0, 0] = vocab['<SOS>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq] + stat, verbose=0)\n",
    "        decoder_concat_input = dense(dec_outputs)\n",
    "\n",
    "        sampled_word_index = np.argmax(decoder_concat_input[0, -1, :])\n",
    "        sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "        if sampled_word != '<EOS> ':\n",
    "            decoded_translation += sampled_word\n",
    "\n",
    "        if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
    "            stop_condition = True\n",
    "\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0, 0] = sampled_word_index\n",
    "        stat = [h, c]\n",
    "\n",
    "    if prepro1 != prev_user_input:\n",
    "        print_chat(prepro1, is_user=True)\n",
    "        prev_user_input = prepro1\n",
    "    print_chat(decoded_translation)\n",
    "\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

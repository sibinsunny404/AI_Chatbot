{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 13, 3027)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "lines = open('movie_lines.txt', encoding='utf-8',\n",
    "             errors='ignore').read().split('\\n')\n",
    "\n",
    "convers = open('movie_conversations.txt', encoding='utf-8',\n",
    "             errors='ignore').read().split('\\n')\n",
    "\n",
    "\n",
    "exchn = []\n",
    "for conver in convers:\n",
    "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n",
    "\n",
    "diag = {}\n",
    "for line in lines:\n",
    "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n",
    "\n",
    "## delete\n",
    "del(lines, convers, conver, line)\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conver in exchn:\n",
    "    for i in range(len(conver) - 1):\n",
    "        questions.append(diag[conver[i]])\n",
    "        answers.append(diag[conver[i+1]])\n",
    "\n",
    "## delete\n",
    "del(diag, exchn, conver, i)\n",
    "\n",
    "\n",
    "###############################\n",
    "#        max_len = 13         #\n",
    "###############################\n",
    "\n",
    "sorted_ques = []\n",
    "sorted_ans = []\n",
    "for i in range(len(questions)):\n",
    "    if len(questions[i]) < 13:\n",
    "        sorted_ques.append(questions[i])\n",
    "        sorted_ans.append(answers[i])\n",
    "\n",
    "\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt\n",
    "\n",
    "clean_ques = []\n",
    "clean_ans = []\n",
    "\n",
    "for line in sorted_ques:\n",
    "    clean_ques.append(clean_text(line))\n",
    "        \n",
    "for line in sorted_ans:\n",
    "    clean_ans.append(clean_text(line))\n",
    "\n",
    "\n",
    "\n",
    "## delete\n",
    "del(answers, questions, line)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n",
    "\n",
    "\n",
    "\n",
    "###############################\n",
    "#                             #\n",
    "###############################\n",
    "\n",
    "del(sorted_ans, sorted_ques)\n",
    "\n",
    "\n",
    "## trimming\n",
    "clean_ans=clean_ans[:30000]\n",
    "clean_ques=clean_ques[:30000]\n",
    "## delete\n",
    "\n",
    "\n",
    "###  count occurences ###\n",
    "word2count = {}\n",
    "\n",
    "for line in clean_ques:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "for line in clean_ans:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "\n",
    "## delete\n",
    "del(word, line)\n",
    "\n",
    "\n",
    "###  remove less frequent ###\n",
    "thresh = 5\n",
    "\n",
    "vocab = {}\n",
    "word_num = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= thresh:\n",
    "        vocab[word] = word_num\n",
    "        word_num += 1\n",
    "        \n",
    "## delete\n",
    "del(word2count, word, count, thresh)       \n",
    "del(word_num)        \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n",
    "\n",
    "\n",
    "\n",
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "x = len(vocab)\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1\n",
    "    \n",
    "    \n",
    "\n",
    "vocab['cameron'] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0\n",
    "\n",
    "## delete\n",
    "del(token, tokens) \n",
    "del(x)\n",
    "\n",
    "### inv answers dict ###\n",
    "inv_vocab = {w:v for v, w in vocab.items()}\n",
    "\n",
    "\n",
    "\n",
    "## delete\n",
    "del(i)\n",
    "\n",
    "\n",
    "\n",
    "encoder_inp = []\n",
    "for line in clean_ques:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "        \n",
    "    encoder_inp.append(lst)\n",
    "\n",
    "decoder_inp = []\n",
    "for line in clean_ans:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])        \n",
    "    decoder_inp.append(lst)\n",
    "\n",
    "### delete\n",
    "del(clean_ans, clean_ques, line, lst, word)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
    "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "decoder_final_output = []\n",
    "for i in decoder_inp:\n",
    "    decoder_final_output.append(i[1:]) \n",
    "\n",
    "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "del(i)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
    "\n",
    "\n",
    "\n",
    "print(decoder_final_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n",
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 249s 255ms/step - loss: 3.1026 - acc: 0.4940\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 75679s 81s/step - loss: 2.7314 - acc: 0.5327\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 191s 203ms/step - loss: 2.5998 - acc: 0.5431\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 159s 170ms/step - loss: 2.5261 - acc: 0.5478\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 155s 165ms/step - loss: 2.4708 - acc: 0.5513\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 2.4229 - acc: 0.5536\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 153s 164ms/step - loss: 2.3779 - acc: 0.5561\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 2.3345 - acc: 0.5585\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 155s 165ms/step - loss: 2.2906 - acc: 0.5605\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 2.2477 - acc: 0.5625\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 2.2050 - acc: 0.5650\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 2.1647 - acc: 0.5671\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 155s 165ms/step - loss: 2.1235 - acc: 0.5696\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 2.0829 - acc: 0.5725\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 158s 168ms/step - loss: 2.0435 - acc: 0.5766\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 156s 166ms/step - loss: 2.0040 - acc: 0.5806\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 150s 160ms/step - loss: 1.9653 - acc: 0.5850\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.9293 - acc: 0.5900\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.8928 - acc: 0.5943\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.8588 - acc: 0.5995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2219756b5d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
    "\n",
    "\n",
    "enc_inp = Input(shape=(13, ))\n",
    "dec_inp = Input(shape=(13, ))\n",
    "\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "embed = Embedding(VOCAB_SIZE+1, output_dim=50, \n",
    "                  input_length=13,\n",
    "                  trainable=True                  \n",
    "                  )\n",
    "\n",
    "\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "enc_op, h, c = enc_lstm(enc_embed)\n",
    "enc_states = [h, c]\n",
    "\n",
    "\n",
    "\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "\n",
    "dense_op = dense(dec_op)\n",
    "\n",
    "model = Model([enc_inp, dec_inp], dense_op)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n",
    "\n",
    "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.8257 - acc: 0.6047\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 150s 160ms/step - loss: 1.7938 - acc: 0.6092\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 1.7636 - acc: 0.6142\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 1.7331 - acc: 0.6188\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 1.7028 - acc: 0.6241\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.6736 - acc: 0.6297\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 1.6453 - acc: 0.6348\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.6174 - acc: 0.6398\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.5904 - acc: 0.6450\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.5634 - acc: 0.6502\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.5377 - acc: 0.6556\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.5111 - acc: 0.6603\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 154s 165ms/step - loss: 1.4864 - acc: 0.6657\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 1.4617 - acc: 0.6703\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 17749s 19s/step - loss: 1.4372 - acc: 0.6753\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 149s 158ms/step - loss: 1.4133 - acc: 0.6802\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 148s 157ms/step - loss: 1.3897 - acc: 0.6857\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.3666 - acc: 0.6907\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.3440 - acc: 0.6956\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 1.3222 - acc: 0.7004\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.3001 - acc: 0.7049\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 151s 161ms/step - loss: 1.2792 - acc: 0.7096\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.2582 - acc: 0.7143\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.2377 - acc: 0.7183\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.2178 - acc: 0.7226\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 154s 164ms/step - loss: 1.1979 - acc: 0.7275\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 156s 166ms/step - loss: 1.1785 - acc: 0.7322\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.1598 - acc: 0.7363\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 152s 162ms/step - loss: 1.1416 - acc: 0.7402\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 153s 163ms/step - loss: 1.1237 - acc: 0.7440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2219af891d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"sequential_5\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 13) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 13) dtype=int32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit([encoder_inp, decoder_inp],decoder_final_output,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filebza1bggn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\sibin\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\engine\\input_spec.py\", line 219, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"sequential_5\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 13) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 13) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\n",
    "enc_model = Model([enc_inp], enc_states)\n",
    "\n",
    "\n",
    "\n",
    "# decoder Model\n",
    "decoder_state_input_h = Input(shape=(400,))\n",
    "decoder_state_input_c = Input(shape=(400,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n",
    "                                    initial_state=decoder_states_inputs)\n",
    "\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "dec_model = Model([dec_inp]+ decoder_states_inputs,\n",
    "                                      [decoder_outputs]+ decoder_states)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"message user-message\" style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background-color: #9cd6d5; text-align: left;\"><span class=\"message-tag\" style=\"font-weight: bold; color: #1E88E5;\">You:</span> hi</div><div class=\"message chatbot-message\" style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background-color: #E0E0E0; text-align: right;\"><span class=\"message-tag\" style=\"font-weight: bold; color: #1E88E5;\">Chatbot:</span> hi </div><div class=\"message user-message\" style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background-color: #9cd6d5; text-align: left;\"><span class=\"message-tag\" style=\"font-weight: bold; color: #1E88E5;\">You:</span> your name</div><div class=\"message chatbot-message\" style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background-color: #E0E0E0; text-align: right;\"><span class=\"message-tag\" style=\"font-weight: bold; color: #1E88E5;\">Chatbot:</span> <OUT> </div><div class=\"message user-message\" style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background-color: #9cd6d5; text-align: left;\"><span class=\"message-tag\" style=\"font-weight: bold; color: #1E88E5;\">You:</span> good luck</div><div class=\"message chatbot-message\" style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background-color: #E0E0E0; text-align: right;\"><span class=\"message-tag\" style=\"font-weight: bold; color: #1E88E5;\">Chatbot:</span> you are not makin a <OUT> with what you <OUT> of </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def print_chat(message, is_user=False):\n",
    "    message_class = \"user-message\" if is_user else \"chatbot-message\"\n",
    "    message_tag = \"You:\" if is_user else \"Chatbot:\"\n",
    "    message_style = \"background-color: #9cd6d5; text-align: left;\" if is_user else \"background-color: #E0E0E0; text-align: right;\"\n",
    "    message_html = f'<div class=\"message {message_class}\" style=\"margin: 10px 0; padding: 10px; border-radius: 5px; {message_style}\">' \\\n",
    "                   f'<span class=\"message-tag\" style=\"font-weight: bold; color: #1E88E5;\">{message_tag}</span> {message}</div>'\n",
    "    chat_history.append(message_html)\n",
    "    display(HTML(message_html))\n",
    "    clear_output(wait=True)\n",
    "    display(HTML(''.join(chat_history)))\n",
    "\n",
    "print(\"#########################################################\")\n",
    "print(\"#       Start Chatting ver. 1.0 (Under training)        #\")\n",
    "print(\"#########################################################\")\n",
    "\n",
    "prepro1 = \"\"\n",
    "prev_user_input = \"\"\n",
    "while prepro1 != 'q':\n",
    "    prepro1 = input(\"You: \")\n",
    "    prepro1 = clean_text(prepro1)\n",
    "    prepro = [prepro1]\n",
    "\n",
    "    txt = []\n",
    "    for x in prepro:\n",
    "        lst = []\n",
    "        for y in x.split():\n",
    "            try:\n",
    "                lst.append(vocab[y])\n",
    "            except:\n",
    "                lst.append(vocab['<OUT>'])\n",
    "        txt.append(lst)\n",
    "\n",
    "    txt = pad_sequences(txt, 13, padding='post')\n",
    "\n",
    "    stat = enc_model.predict(txt, verbose=0)\n",
    "\n",
    "    empty_target_seq = np.zeros((1, 1))\n",
    "    empty_target_seq[0, 0] = vocab['<SOS>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        dec_outputs, h, c = dec_model.predict([empty_target_seq] + stat, verbose=0)\n",
    "        decoder_concat_input = dense(dec_outputs)\n",
    "\n",
    "        sampled_word_index = np.argmax(decoder_concat_input[0, -1, :])\n",
    "        sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "        if sampled_word != '<EOS> ':\n",
    "            decoded_translation += sampled_word\n",
    "\n",
    "        if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
    "            stop_condition = True\n",
    "\n",
    "        empty_target_seq = np.zeros((1, 1))\n",
    "        empty_target_seq[0, 0] = sampled_word_index\n",
    "        stat = [h, c]\n",
    "\n",
    "    if prepro1 != prev_user_input:\n",
    "        print_chat(prepro1, is_user=True)\n",
    "        prev_user_input = prepro1\n",
    "    print_chat(decoded_translation)\n",
    "\n",
    "clear_input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
